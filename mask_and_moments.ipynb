{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mask_and_moments.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSedlzBOvQBm",
        "colab_type": "text"
      },
      "source": [
        "Make signal and moment masks for the dwarf galaxies.\n",
        "\n",
        "Read in the paths from  the `Content` sheet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCYziXpM0xI8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade --quiet gspread"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrgceW9_waLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% pip install --upgrade --quiet astropy\n",
        "% pip install --quiet spectral_cube\n",
        "% pip install --quiet reproject\n",
        "% pip install --quiet scikit-image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekXHsNdnxbDB",
        "colab_type": "code",
        "outputId": "973d7f81-66f8-4a38-db09-4223f09dbaa8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Now install stuff needed for CubeAnalysis\n",
        "% pip install --quiet sphinx==1.5.6  # avoid issue when creating wheels from repos. https://github.com/sphinx-doc/sphinx/issues/3976\n",
        "% pip install --quiet FITS_tools image_tools\n",
        "% pip install --quiet git+https://github.com/radio-astro-tools/uvcombine.git\n",
        "% pip install --quiet git+https://github.com/e-koch/CubeAnalysis.git"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for uvcombine (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for cube-analysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xr3o1haBzSAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "64625190-39aa-44f7-f41c-630303aa8b5a"
      },
      "source": [
        "# Make sure this works\n",
        "from cube_analysis import run_pipeline\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: AstropyDeprecationWarning: astropy.extern.six will be removed in 4.0, use the six module directly if it is still needed [astropy.extern.six]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sR4V8zRPvMK1",
        "colab_type": "code",
        "outputId": "7edb5d78-3c34-4cae-fce5-12d00cbb5458",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "# Mount shared drive\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZoobfmJ-v0lF",
        "colab_type": "code",
        "outputId": "63d86c50-350c-490f-fa12-f8f17d4e5670",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "%cd Shared drives/LocalGroup-VLA\n",
        "%ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/gdrive/Shared drives/LocalGroup-VLA\n",
            "'Code links.gdoc'   feather.ipynb   \u001b[0m\u001b[01;34mM31\u001b[0m/   mask_and_moments.ipynb   \u001b[01;34mSextansA\u001b[0m/\n",
            " Content.gsheet     \u001b[01;34mIC1613\u001b[0m/         \u001b[01;34mM33\u001b[0m/   quicklooks.ipynb         \u001b[01;34mWLM\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfu7MvBg0R1h",
        "colab_type": "text"
      },
      "source": [
        "Open the Content sheet to get paths that will be run."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bkl-biys1FFc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "\n",
        "gc = gspread.authorize(GoogleCredentials.get_application_default())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-Vh37I00Qlu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "content_path = '1Dmkioi_BaCdCR-WdPJvqrCwjqQ_aSrIXq0Od9LT8PFg'\n",
        "\n",
        "worksheet = gc.open_by_key(content_path).sheet1\n",
        "\n",
        "# get_all_values gives a list of rows.\n",
        "rows = worksheet.get_all_values()\n",
        "# print(rows)\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame.from_records(rows)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pSAiaXa0ZPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWOehpm40ZU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string\n",
        "from datetime import datetime\n",
        "\n",
        "def update_mask_moments(row, is_feather=False):\n",
        "    \n",
        "    # Sign mask and moments in the worksheet with\n",
        "    # date + time\n",
        "\n",
        "    if not is_feather:\n",
        "        col_idx = np.where(colnames == 'Path')[0][0] + 1\n",
        "        col_idx_mask = np.where(colnames == 'Signal mask')[0][0]\n",
        "        col_idx_moments = np.where(colnames == 'Moments')[0][0]\n",
        "    else:\n",
        "        col_idx = np.where(colnames == 'Feather Path')[0][0] + 1\n",
        "        col_idx_mask = np.where(colnames == 'Signal mask feather')[0][0]\n",
        "        col_idx_moments = np.where(colnames == 'Moments feather')[0][0]\n",
        "\n",
        "    col_letter_mask = string.ascii_uppercase[col_idx_mask]\n",
        "    col_letter_moments = string.ascii_uppercase[col_idx_moments]\n",
        "\n",
        "    now = datetime.now()\n",
        "    \n",
        "    worksheet.update_acell(f\"{col_letter_mask}{row}\", now.strftime(\"%Y-%m-%d %H:%M\"))\n",
        "    worksheet.update_acell(f\"{col_letter_moments}{row}\", now.strftime(\"%Y-%m-%d %H:%M\"))\n",
        "\n",
        "# worksheet.update_acell('L2', 'HI!')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmwZpLMEIEi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test worksheet update\n",
        "# update_mask_moments(2, is_feather=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbnm-cErJdSC",
        "colab_type": "text"
      },
      "source": [
        "Get the list of VLA-only cubes to run in the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TT15L1QT0ZR9",
        "colab_type": "code",
        "outputId": "a1e08ac8-b97f-442b-95e8-adf194b557a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "colnames = np.array(worksheet.row_values('A'))\n",
        "paths_idx = np.where(colnames == 'Path')[0][0] + 1\n",
        "runcolab_idx = np.where(colnames == 'Colab_maskmoments')[0][0] + 1\n",
        "rms_idx = np.where(colnames == '1-sigma Noise (K)')[0][0] + 1\n",
        "coldens_idx = np.where(colnames == '3-sigma HI column density (cm^-2)')[0][0] + 1\n",
        "\n",
        "paths = worksheet.col_values(paths_idx)\n",
        "run_in_colab = worksheet.col_values(runcolab_idx)\n",
        "paths\n",
        "# run_in_colab"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Path',\n",
              " '',\n",
              " 'WLM/VLA/13A-213/HI/full_imaging_noSD',\n",
              " 'WLM/VLA/13A-213/HI/full_imaging_wcont_noSD',\n",
              " 'WLM/VLA/13A-213/HI/full_imaging_robust0_noSD',\n",
              " '',\n",
              " 'IC1613/VLA/13A-213/HI/full_imaging_noSD',\n",
              " 'IC1613/VLA/13A-213/HI/full_imaging_wcont_noSD',\n",
              " '',\n",
              " '',\n",
              " 'SextansA/VLA/13A-213/HI/full_imaging_noSD',\n",
              " 'SextansA/VLA/13A-213/HI/full_imaging_CDtaper_noSD',\n",
              " 'SextansA/VLA/13A-213/HI/full_imaging_Cconfig_noSD',\n",
              " '',\n",
              " '',\n",
              " '',\n",
              " 'M33/VLA/14B-088/HI/full_imaging_noSD/']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qa8TdpmwAZb",
        "colab_type": "code",
        "outputId": "3a967cb8-498d-4d41-dfc6-f9ff70d319ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "source": [
        "from astropy import log\n",
        "import astropy.units as u\n",
        "from astropy.io import fits\n",
        "from glob import glob\n",
        "import os\n",
        "from spectral_cube import SpectralCube\n",
        "from decimal import Decimal\n",
        "\n",
        "from cube_analysis import run_pipeline\n",
        "from cube_analysis.masking import noise_estimation\n",
        "\n",
        "\n",
        "num_cores = 1\n",
        "\n",
        "for row, (path, run_colab) in enumerate(zip(paths, run_in_colab)):\n",
        "    \n",
        "    if len(path) == \"\":\n",
        "        continue\n",
        "\n",
        "    if run_colab != \"T\":\n",
        "        continue\n",
        "        \n",
        "    now = datetime.now()\n",
        "    time_string = now.strftime(\"%Y-%m-%d-%H-%M\")\n",
        "        \n",
        "    log_file = os.path.join(path, f'log_mask_and_moments_{time_string}.log')\n",
        "    with log.log_to_file(log_file):\n",
        "\n",
        "        log.info(f\"Running on cube from: {path}\")\n",
        "        \n",
        "        cube_name = glob(os.path.join(path, \"*image.pbcor.fits\"))\n",
        "        assert len(cube_name) == 1\n",
        "        cube_name = cube_name[0]\n",
        "        log.info(f\"Found cube name: {cube_name}\")\n",
        "        \n",
        "        pb_name = glob(os.path.join(path, \"*pb.fits\"))\n",
        "        assert len(pb_name) == 1\n",
        "        pb_name = pb_name[0]\n",
        "        log.info(f\"Found pb name: {pb_name}\")\n",
        "    \n",
        "        # Convert the cube to K\n",
        "        cube_K_name = f\"{cube_name.rstrip('.fits')}_K.fits\"\n",
        "    \n",
        "        log.info(\"Convert cube to K.\")\n",
        "        if not os.path.exists(cube_K_name):\n",
        "            cube = SpectralCube.read(cube_name, memmap=False)    \n",
        "            cube.allow_huge_operations = True\n",
        "    \n",
        "            cube = cube.to(u.K)\n",
        "            cube.write(cube_K_name)\n",
        "            \n",
        "            del cube\n",
        "        else:\n",
        "            log.info(\"Found existing K cube.\")\n",
        "    \n",
        "        # Convolve to a common beam size\n",
        "        cube = SpectralCube.read(cube_K_name)\n",
        "        if hasattr(cube, 'beams'):\n",
        "            log.info(\"Convolving to a common beam size.\")\n",
        "            com_beam = cube.beams.common_beam()\n",
        "            cube.allow_huge_operations = True\n",
        "            cube = cube.convolve_to(com_beam)\n",
        "            # Overwrite K cube\n",
        "            cube.write(cube_K_name, overwrite=True)\n",
        "        del cube\n",
        "    \n",
        "        # VLA-only cube\n",
        "        log.info(\"Masking and moments for the VLA-only cube\")\n",
        "        \n",
        "        # Seem to have issue creating a FITS file to stream to.\n",
        "        # Try making an empty file first.\n",
        "        mask_name = f\"{cube_K_name.rstrip('.fits')}_source_mask.fits\"\n",
        "        # touch {mask_name}\n",
        "        \n",
        "#         hdulist = fits.HDUList([fits.PrimaryHDU()])\n",
        "#         hdulist.writeto(mask_name, 'exception')\n",
        "        \n",
        "        run_pipeline(cube_K_name,\n",
        "                     path,\n",
        "                     pb_file=pb_name,\n",
        "                     pb_lim=0.15,\n",
        "                     apply_pbmasking=False,\n",
        "                     convolve_to_common_beam=False,\n",
        "                     masking_kwargs={\"method\": \"ppv_connectivity\",\n",
        "                                      \"save_cube\": True,\n",
        "                                      \"is_huge\": False,\n",
        "                                      \"smooth_chans\": 5,\n",
        "                                      \"min_chan\": 5,\n",
        "                                      \"peak_snr\": 4.,\n",
        "                                      \"min_snr\": 2,\n",
        "                                      \"edge_thresh\": 1,\n",
        "                                      \"pb_map_name\": pb_name,\n",
        "                                     },\n",
        "                     moment_kwargs={\"num_cores\": num_cores,\n",
        "                                    \"verbose\": True,\n",
        "                                    \"chunk_size\": 1e5,\n",
        "                                    \"make_peakvels\": True},\n",
        "                     combeam_kwargs={})\n",
        "\n",
        "\n",
        "        log.info(\"Update google sheet w/ write times\")\n",
        "        \n",
        "        update_mask_moments(row, is_feather=False)\n",
        "        \n",
        "        # Calculate the noise in the cube, w/o the signal region\n",
        "        mask_name = glob(os.path.join(path, \"*source_mask.fits\"))\n",
        "        assert len(mask_name) == 1\n",
        "        mask_name = mask_name[0]\n",
        "        \n",
        "        noise_rms, coldens_hi = noise_estimation(cube_K_name, pb_name,\n",
        "                                                 mask_name)\n",
        "        \n",
        "        # Input noise estimation and 3-sigma column density estimation\n",
        "        # The latter uses the per-channel sensitivity\n",
        "        log.info(\"Input noise and column density estimations.\")\n",
        "        col_letter_rms = string.ascii_uppercase[rms_idx]\n",
        "        col_letter_coldens = string.ascii_uppercase[coldens_idx]\n",
        "        worksheet.update_acell(f\"{col_letter_rms}{row}\", '{:.2e}'.format(noise_rms))\n",
        "        worksheet.update_acell(f\"{col_letter_coldens}{row}\",\n",
        "                               '{:.2e}'.format(3 * coldens_hi))\n",
        "        \n",
        "        \n",
        "        print(argh)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Running on cube from: WLM/VLA/13A-213/HI/full_imaging_noSD [unknown]\n",
            "INFO: Found cube name: WLM/VLA/13A-213/HI/full_imaging_noSD/WLM_13A-213_HI_spw_0.clean.image.pbcor.fits [unknown]\n",
            "INFO: Found pb name: WLM/VLA/13A-213/HI/full_imaging_noSD/WLM_13A-213_HI_spw_0.clean.pb.fits [unknown]\n",
            "INFO: Convert cube to K. [unknown]\n",
            "INFO: Found existing K cube. [unknown]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/astropy/convolution/convolve.py:768: RuntimeWarning: invalid value encountered in true_divide\n",
            "  rifft = (ifftn(fftmult)) / bigimwt\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5MkMVGHSaSr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "    # VLA+GBT cube\n",
        "    log.info(\"Masking and moments for the VLA+EBHIS cube\")\n",
        "    run_pipeline(fourteenA_HI_data_wEBHIS_path(\"M31_14A_HI_contsub_width_04kms.image.pbcor.EBHIS_feathered.fits\"),\n",
        "                 fourteenA_HI_data_wEBHIS_path(\"\", no_check=True),\n",
        "                 pb_file=fourteenA_HI_data_path(\"M31_14A_HI_contsub_width_04kms.pb.fits\"),\n",
        "                 pb_lim=0.05,\n",
        "                 apply_pbmasking=False,\n",
        "                 convolve_to_common_beam=False,\n",
        "                 masking_kwargs={\"method\": \"ppv_connectivity\",\n",
        "                                 \"save_cube\": True,\n",
        "                                 \"is_huge\": True,\n",
        "                                 \"smooth_chans\": 17,\n",
        "                                 \"min_chan\": 5,\n",
        "                                 \"peak_snr\": 4.,\n",
        "                                 \"min_snr\": 2,\n",
        "                                 \"edge_thresh\": 1,\n",
        "                                 \"pb_map_name\": fourteenA_HI_data_path(\"M31_14A_HI_contsub_width_04kms.pb.fits\")\n",
        "                                 },\n",
        "                 moment_kwargs={\"num_cores\": num_cores,\n",
        "                                \"verbose\": True,\n",
        "                                \"chunk_size\": 1e5,\n",
        "                                \"make_peakvels\": False},\n",
        "                 combeam_kwargs={})"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}